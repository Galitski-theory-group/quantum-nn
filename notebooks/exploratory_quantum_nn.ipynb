{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "import json\n",
    "import scipy.stats\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "a=0.5\n",
    "g=np.pi/2\n",
    "\n",
    "bias=False\n",
    "num_shots=15\n",
    "n_epochs = 100\n",
    "step=100\n",
    "batch_size_train = 64\n",
    "batch_size_test = 10000\n",
    "learning_rate = 1e-2\n",
    "momentum = 0.9\n",
    "input_size=28**2\n",
    "output_size=10\n",
    "depth=2\n",
    "width=10\n",
    "\n",
    "train_size=5000\n",
    "test_size=10000\n",
    "\n",
    "class WMeasure_Rot_Fun(autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx,input,angles,last_res,a,g):\n",
    "        ctx.save_for_backward(input)\n",
    "        \n",
    "        if a==0.0:\n",
    "            thetas=torch.pi/2*(last_res-torch.sign(input))\n",
    "        else:\n",
    "            thetas=torch.pi/2*(last_res-F.tanh(input/a))\n",
    "\n",
    "        temp_angles=angles+thetas\n",
    "        \n",
    "        betas=torch.sin(temp_angles/2)\n",
    "        exp_z=torch.cos(temp_angles/2)**2-betas**2\n",
    "        exp_z_anc=exp_z*torch.sin(g)\n",
    "\n",
    "        probs=torch.stack([(1+exp_z_anc)/2,(1-exp_z_anc)/2],2)\n",
    "        probs = torch.clamp(probs, min=0)\n",
    "        outcomes=torch.tensor([1.0,-1.0])\n",
    "        meas_res=outcomes[torch.distributions.Categorical(probs,validate_args=False).sample()]\n",
    "        last_res.copy_(meas_res)\n",
    "        \n",
    "        side=betas*torch.sqrt((1-meas_res*torch.sin(g))/(1+meas_res*exp_z_anc))\n",
    "        side=torch.clamp(side,min=-1,max=1)\n",
    "        new_angles=2*torch.arcsin(side)\n",
    "        angles.copy_(new_angles)\n",
    "\n",
    "        return meas_res\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx,grad_output):\n",
    "        preacts,=ctx.saved_tensors\n",
    "        ones=torch.ones_like(preacts)\n",
    "        ind=torch.logical_and(preacts>-ones,preacts<ones).float()\n",
    "        return ind*grad_output, None, None, None, None\n",
    "\n",
    "class WMeasure_Rot(nn.Module):\n",
    "    def __init__(self,angles,last_res,a,g):\n",
    "        super(WMeasure_Rot,self).__init__()\n",
    "        self.a=torch.tensor(a)\n",
    "        self.g=torch.tensor(g)\n",
    "        self.angles=angles\n",
    "        self.last_res=last_res\n",
    "    def forward(self,input):\n",
    "        return WMeasure_Rot_Fun.apply(input,self.angles,self.last_res,self.a,self.g)\n",
    "\n",
    "class StepHTFunction(autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.save_for_backward(input)\n",
    "        return ((input > 0).float()-0.5)*2\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input,=ctx.saved_tensors\n",
    "        ones=torch.ones(input.size())\n",
    "        ind=torch.logical_and(input>-ones,input<ones).float()\n",
    "        return ind*grad_output\n",
    "\n",
    "class StepHT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StepHT, self).__init__()\n",
    "    def forward(self, x):\n",
    "        x = StepHTFunction.apply(x)\n",
    "        return x\n",
    "\n",
    "class FCN(nn.Module):\n",
    "    def __init__(self,width,depth,in_size,out_size):\n",
    "        super(FCN,self).__init__()\n",
    "        self.width=width\n",
    "        self.angles=torch.tensor([])\n",
    "        self.last_res=torch.tensor([])\n",
    "        \n",
    "        layers=[nn.Linear(in_size,width,bias=bias)]\n",
    "        for _ in range(depth-2):\n",
    "            layers.append(WMeasure_Rot(self.angles,self.last_res,a,g))\n",
    "            layers.append(nn.Linear(width,width,bias=bias))\n",
    "        layers.append(WMeasure_Rot(self.angles,self.last_res,a,np.pi/2))\n",
    "        layers.append(nn.Linear(width,out_size,bias=bias))\n",
    "        self.fcn=nn.Sequential(*layers)\n",
    "\n",
    "    def prepare(self,x):\n",
    "        temp_angles=torch.zeros((x.shape[0],self.width))\n",
    "        self.angles.resize_(temp_angles.shape).copy_(temp_angles)\n",
    "    \n",
    "        temp_res=torch.ones((x.shape[0],self.width))\n",
    "        self.last_res.resize_(temp_res.shape).copy_(torch.ones_like(temp_res))\n",
    "    \n",
    "    def forward(self,x):\n",
    "        self.prepare(x)\n",
    "        return self.fcn(x)\n",
    "\n",
    "class Det_FCN(nn.Module):\n",
    "  def __init__(self,width,depth,in_size,out_size):\n",
    "    super(Det_FCN,self).__init__()\n",
    "    layers=[nn.Linear(in_size,width,bias=bias),StepHT()]\n",
    "    for _ in range(depth-2):\n",
    "      layers.append(nn.Linear(width,width,bias=bias))\n",
    "      layers.append(StepHT())\n",
    "    layers.append(nn.Linear(width,out_size,bias=bias))\n",
    "    # layers.append(act_fun(a))\n",
    "    self.fcn=nn.Sequential(*layers)\n",
    "    return\n",
    "\n",
    "  def forward(self,x):\n",
    "    return self.fcn(x)\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.kaiming_normal_(m.weight,nonlinearity='linear')\n",
    "\n",
    "train_set = datasets.MNIST('data/', train=True, download=True, \n",
    "                            transform=transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                                torch.flatten\n",
    "                             ]))\n",
    "train_set=torch.utils.data.Subset(train_set,range(0,train_size))\n",
    "train_loader = torch.utils.data.DataLoader(train_set,batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_set = datasets.MNIST('data/', train=False, download=True,\n",
    "                             transform=transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                                 torch.flatten\n",
    "                             ]))\n",
    "test_set=torch.utils.data.Subset(test_set,range(0,test_size))\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size_test, shuffle=False)\n",
    "\n",
    "def get_err(loader,model,num_shots):\n",
    "    batch_err=[]\n",
    "    for imgs, labels in loader:\n",
    "        preds_coll=[torch.argmax(model(imgs),axis=1) for _ in range(num_shots)]\n",
    "        preds=torch.tensor(scipy.stats.mode(preds_coll, axis=0, keepdims=False)[0])\n",
    "        vec=(preds!=labels)\n",
    "        batch_err.append(sum(vec)/len(preds))\n",
    "    return np.mean(batch_err)\n",
    "\n",
    "def get_err_y(ys,labels,num_shots):\n",
    "    preds_coll=[torch.argmax(ys,axis=1) for _ in range(num_shots)]\n",
    "    preds=torch.tensor(scipy.stats.mode(preds_coll, axis=0, keepdims=False)[0])\n",
    "    vec=(preds!=labels)\n",
    "    return sum(vec)/len(ys)\n",
    "\n",
    "net=FCN(width,depth,input_size,output_size)\n",
    "det_net=Det_FCN(width,depth,input_size,output_size)\n",
    "net.apply(init_weights)\n",
    "det_net.load_state_dict(net.state_dict())\n",
    "loss=nn.CrossEntropyLoss()\n",
    "optimizer=optim.SGD(net.parameters(),lr=learning_rate,momentum=momentum)\n",
    "\n",
    "first_params=[param.detach().tolist() for param in net.parameters()]\n",
    "# param_list=[]\n",
    "# params=[param.detach().tolist() for param in net.parameters()]\n",
    "# param_list.append(params)\n",
    "losses=[]\n",
    "# rates=[scheduler.get_last_lr()]\n",
    "err_rates=[float(get_err(test_loader,net,num_shots))]\n",
    "train_err_rates=[float(get_err(train_loader,net,num_shots))]\n",
    "det_err_rates=[float(get_err(test_loader,det_net,num_shots))]\n",
    "det_net=FCN(width,depth,input_size,output_size)\n",
    "\n",
    "first=True\n",
    "step_count=0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_errs=[]\n",
    "    for i, (imgs, labels) in enumerate(train_loader):\n",
    "        imgs.requires_grad_(True)\n",
    "        labels=labels.type(dtype=torch.long)\n",
    "        optimizer.zero_grad()\n",
    "        #forward pass\n",
    "        Y_preds=net(imgs)\n",
    "        if epoch%step==step-1:\n",
    "            with torch.no_grad(): \n",
    "                train_errs.append(get_err_y(Y_preds,labels,1))\n",
    "\n",
    "        loss_step=loss(Y_preds,labels)\n",
    "        \n",
    "        #comment out to not save first loss\n",
    "        if first:\n",
    "            losses.append(float(loss_step.detach().numpy()))\n",
    "            first=False\n",
    "\n",
    "        #backward pass\n",
    "        loss_step.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch%step==step-1:\n",
    "        losses.append(float(loss_step.detach().numpy()))\n",
    "        # params=[param.detach().tolist() for param in net.parameters()]\n",
    "        # param_list.append(params)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            err_rates.append(float(get_err(test_loader,net,num_shots)))\n",
    "            train_err_rates.append(float(np.mean(train_errs)))\n",
    "        det_net.load_state_dict(net.state_dict())\n",
    "        det_err_rates.append(float(get_err(test_loader,det_net,1)))\n",
    "\n",
    "last_params=[param.detach().tolist() for param in net.parameters()]\n",
    "\n",
    "with torch.no_grad():\n",
    "    acc=1-get_err(test_loader,net,num_shots)\n",
    "\n",
    "out_dict={\n",
    "    \"a\": a,\n",
    "    \"g\": g,\n",
    "    \"num_shots\": num_shots,\n",
    "    \"train_size\": train_size,\n",
    "    \"test_size\": test_size,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"momentum\": momentum,\n",
    "    \"batch_size\": batch_size_train,\n",
    "    \"epochs\": n_epochs,\n",
    "    \"input_size\": input_size,\n",
    "    \"output_size\": output_size,\n",
    "    \"depth\": depth,\n",
    "    \"width\": width,\n",
    "    \"test_accuracy\": acc,\n",
    "    \"losses\": losses,\n",
    "    \"err_rates\": err_rates,\n",
    "    \"train_err_rates\": train_err_rates,\n",
    "    \"det_err_rates\": det_err_rates,\n",
    "    \"step\": step,\n",
    "    \"first_params\":first_params,\n",
    "    \"last_params\":last_params\n",
    "}\n",
    "\n",
    "with open(\"data/test.json\",\"w\") as outfile:\n",
    "    json.dump(out_dict,outfile)\n",
    "\n",
    "print(\"acc:\"+str(acc))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".quantum_nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
